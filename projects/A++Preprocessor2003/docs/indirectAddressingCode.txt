Hi,
   Here is an example parallel interpolation operator.  I know 
that this has become an interesting topic all of a sudden.  Brian
and I defined an interface for parallel indirect addressing low level support
and Brian was working on it about the time that Steffan was trying to built
similar code for this thesis work.  Brian was able to finish the 
low level parallel indirect addressing support in the summer of 2000.
I have not got around to building the higher level interface to use this
code within P++ at the high levels (since that requires some significant
time to complete).

   My argument for the last week has been that an interpolation operator
is very easy to build out of the low level indirect addressing support in P++
which Brian wrote.  In revisiting the code Brian and I decided that the 
interfaces needed a little work and Brian had to do a little work to get the
test codes from 18 months ago to compile and run (the usual story, software rusts).

   The following example code demonstrates a parallel interpolation operator,  it essentially
does the communication up front to build serial arrays, expresses the interpolation operator
as an operation on serial arrays, and then does the communication to assign the result
to the Lhs.  There are 2 things, maybe more if we look carefully, that
could be done to improve on the efficiency (depending on the distributions of the input
parallel arrays):  1) the serial array operations could be written at a still lower level
(I elected to skip that optimization since ROSE could in principal do that
automatically (but I have not tried the preprocessor on this code yet)).
2) the location of the data where the serial operations representing the 
interpolation operator could be different (though at the moment this is not
possible with the P++ low level indirect addressing support without more
work on a different implementation of a parallel interpolation operator, or more
work to the low level support (long planned for phase II of the indirect addressing
support)).

   The following code implements a linear interpolation operator
(and several simplified non-interpolation operators, for debugging and to see
the more general idea).  It runs with a new version of P++ which I will check into
the CVS repository shortly.  It seems to have passed all of the automated
multi-platform tests.  This code is meant to provide a more specific
example of parallel interpolation in P++ (implemented using the low level
interfaces) and compliments the existing test codes in the P++/IndirectAddressing
directory which only test the separate pieces of the low level support.
The attached test code puts them together so that it is more clear how one can use them
to implement parallel interpolation in P++.  I wrote it to demonstrate how
much of what is needed is there, and to become more familiar with the details
of what Brian did and is doing relative to this work.  

   There are several ways to implement parallel indirect addressing, I think this
is the shortest (outside of using scalar indirect addressing, which would be 
REALLY slow, bug shorter still).  There are even other ways to use the P++ low level support for 
indirect addressing to build specialized parallel interpolation operators which
would use different distributions and have other properties (advantages/disadvantages).
The code below is, I think, the shortest possible parallel indirect addressing operator
expressible in the P++ low level interface.  Depending on how you count it, it is 
only 10-20 lines of code!

  Most of the actual code below is the test code for the interpolation operator.
I also created a class to organize the data for each operand, there would be 
countless ways to put this together, I selected an approach which would be simple
to understand (and debug).  The code took about two hours to write, I had to relearn
some of the low level interface issues, but took longer to debug and make run 
cleanly through purify (on different numbers of preprocessors).  I had to fix
some details in P++, the low level indirect addressing code itself, and a line 
or two of the example source code for the interpolation operator.

   Since I was able to so easily get this example written and working, it is
clearly because the low level code had been well written and very well tested
by Brian 18 months ago. So Brian gets the credit for all that.

Have fun, playing with the different ways of writing parallel interpolation operators,
Dan


P.S. I also discovered in writing this example code that the low level indirect addressing 
     support code only works currently for 2D problems.  It seems it is an easy fix to
     correct this so that it will also work for multiple dimensions and Brian is working on this
     presently.  I discovered the hard way that 1D does not work, so if your playing with
     the low level code you should stick to 2D examples for the moment.  This will be fixed shortly.


Example Interpolation Source code:
// Set this to 1, 2, 3, or 4 to test different numbers of operands
// This is still a simple case of implementing the communication
// required for parallel interpolation.  Only the case of 4 operands
// really implements an interpolation formula (1D linear interpolation).
#define NUMBER_OF_OPERANDS 4

#include "CommunicationScheduler.h"

class IndirectAddressingOperand
   {
  // This class is used to simplify the treatment of each operand
  // int a statement that requires parallel indirect addressing

     public:
       // Data required for parallel support of each operand
          floatArray* dataArrayPtr;
          vector<intArray*> indirectionArrayList;
          floatArray* temporaryArrayPtr;

          CommunicationScheduler<float,floatArray> messageScheduler;

       // destructor
         ~IndirectAddressingOperand ();

       // constructor
          IndirectAddressingOperand ( floatArray* arrayPtr,
                                      vector<intArray*> indirectionVectors,
                                      bool isLhsOperand = FALSE );

     private:
          IndirectAddressingOperand ();
          IndirectAddressingOperand (const IndirectAddressingOperand & X);
          IndirectAddressingOperand & operator= (const IndirectAddressingOperand & X);
   };

IndirectAddressingOperand::
~IndirectAddressingOperand ()
   {
  // Destructor
  // Since we don't increment the reference counts for these we don't have to delete them
  // (except for the temporaryArrayPtr which we build in the IndirectAddressingOperand constructor)

  // delete dataArrayPtr;
     dataArrayPtr = NULL;
  // delete indirectionArrayList[0];
     indirectionArrayList[0] = NULL;
  // delete indirectionArrayList[1];
     indirectionArrayList[1] = NULL;
     delete temporaryArrayPtr;
     temporaryArrayPtr = NULL;
   }

IndirectAddressingOperand::
IndirectAddressingOperand ( floatArray* arrayPtr, vector<intArray*> inputIndirectionArrayList, bool isLhsOperand )
   {
  // Constructor to assemble all the information for each operand

     APP_ASSERT (arrayPtr != NULL);
     dataArrayPtr = arrayPtr;
     for (int i=0; i < arrayPtr->numberOfDimensions(); i++)
        {
          indirectionArrayList.push_back( inputIndirectionArrayList[i] );
        }

     if (isLhsOperand == TRUE)
        {
       // Process the Lhs a little differently (build a null array and compute a different schedule)
          temporaryArrayPtr = new floatArray(inputIndirectionArrayList[0]->getLength(0));
          APP_ASSERT (temporaryArrayPtr != NULL);
          APP_ASSERT (temporaryArrayPtr->getLength(0) == inputIndirectionArrayList[0]->getLength(0));

       // Initialized local array representing lhs (not required, but done to simplify debugging)
          *temporaryArrayPtr = 0;

       // Compute the communication schedule (communicates the indirection arrays as required)
          messageScheduler.computeScheduleForAofIequalsT( arrayPtr, inputIndirectionArrayList , temporaryArrayPtr );
        }
       else
        {
       // T is created aligned like J and the same size
       // Build a null array and then redim using the Array_Domain (need a more efficient way to handle this)
          temporaryArrayPtr = new floatArray();
          APP_ASSERT (temporaryArrayPtr != NULL);
          APP_ASSERT (inputIndirectionArrayList[0] != NULL);
          temporaryArrayPtr->redim(inputIndirectionArrayList[0]->getDomain()); 
          temporaryArrayPtr->setBase(APP_Global_Array_Base);

       // Build T to have the same distribution as J (not the optimimal distribution)
       // (all the J_i are assumed to have the same distribution)
          messageScheduler.computeScheduleForTequalsBofJ(temporaryArrayPtr,arrayPtr,inputIndirectionArrayList);
        }
   }

void
interpolate (
   int numberOfOperands,
   vector<floatArray*> arrayOfOperands,
   vector<vector<intArray*> > indirectionArrayListForOperands )
   {
  // This function takes the Lhs and an array of Rhs operands and does the
  // communication required to send them to a common location (same distribution as 
  // the indirect arrays, which is not optimal for interpolation) so that the multiple
  // parallel distributed arrays are built (each with the same distribution).  Then 
  // the parallel arrays are operated upon to required parallel arithmetic statement
  // (interpolation).  Since the arrays have the same distribution we can implement the
  // statement using the serial arrays on each processor.  A more efficient implentation
  // could just address the data directly.

     int i = 0;

  // List of operands for expression: operandList[0](I) = operandList[1](I) + operandList[2] + ... + operandList[n];
     vector<IndirectAddressingOperand*> operandList;

  // Build the operandList (the lhs is assumed to be the first element)
     bool isLhsOperand = TRUE;
     for (i=0; i < numberOfOperands; i++)
        {
          IndirectAddressingOperand* operand =
               new IndirectAddressingOperand (arrayOfOperands[i],indirectionArrayListForOperands[i],isLhsOperand);
          APP_ASSERT (operand != NULL);

       // Assemble the list of pointers
          operandList.push_back(operand);

       // All of the next operatns will be RHS operands
          isLhsOperand = FALSE;
        }

  // execute the schedule for the Rhs operands to do the communication (e.g. T = B(J))
     for (i=1; i < operandList.size(); i++)
        {
          operandList[i]->messageScheduler.executeScheduleForTequalsBofJ(indirectionArrayListForOperands[i]);
        }

  // Parallel array operation to form rhs parallel array (not using indirect addressing)
  // If all of the rhs operands have the same distribution then this operation could be 
  // implemented at a lower level using A++ serial arrays (or a lower level by accessing the data directly)
#if (NUMBER_OF_OPERANDS == 1)
     *(operandList[0]->temporaryArrayPtr) = 1;
#endif
#if (NUMBER_OF_OPERANDS == 2)
     *(operandList[0]->temporaryArrayPtr) = *(operandList[1]->temporaryArrayPtr);
#endif
#if (NUMBER_OF_OPERANDS == 3)
     *(operandList[0]->temporaryArrayPtr) = *(operandList[1]->temporaryArrayPtr) + *(operandList[2]->temporaryArrayPtr);
#endif
#if (NUMBER_OF_OPERANDS == 4)
     *(operandList[0]->temporaryArrayPtr) =
          *(operandList[1]->temporaryArrayPtr) * *(operandList[2]->temporaryArrayPtr) +
          (1.0 - *(operandList[1]->temporaryArrayPtr)) * *(operandList[3]->temporaryArrayPtr);
#endif

#if (NUMBER_OF_OPERANDS > 0)
  // execute this schedule to complete the communication to assign the 
  // temporary to the Lhs (e.g. A(I) = T)
     operandList[0]->messageScheduler.executeScheduleForAofIequalsT(indirectionArrayListForOperands[0]);
#endif

  // Clean up the allocated memory
     for (i=0; i < numberOfOperands; i++)
        {
          delete operandList[i];
          operandList[i] = NULL;
        }
   }

void
interpolationTest()
   {
  // Test the low level P++ indirect addressing
  // Since on multiple processors the 1D indirection arrays and the 2D arrays
  // to be indirectly indexed will be distributed differently, this simple
  // example should test a reasonable cross-section of parallel cases.

  // Build the indirection arrays to be SIZE and the arrays to be indirectly indexed to be SIZE x SIZE
     const int SIZE = 12;

  // Build parallel arrays for the indirection arrays
  // and the arrays to be indirectly indexed
     intArray   I1(SIZE);
     intArray   J1(SIZE);
     intArray   K1(SIZE);
     intArray   L1(SIZE);
     intArray   I2(SIZE);
     intArray   J2(SIZE);
     intArray   K2(SIZE);
     intArray   L2(SIZE);
     floatArray A(SIZE,SIZE);
     floatArray B(SIZE,SIZE);
     floatArray C(SIZE,SIZE);
     floatArray D(SIZE,SIZE);

  // Use serial arrays and compute the exact solution so we can 
  // compare the serail and parallel solutions at the end
     intSerialArray   exactI1(SIZE);
     intSerialArray   exactJ1(SIZE);
     intSerialArray   exactK1(SIZE);
     intSerialArray   exactL1(SIZE);
     intSerialArray   exactI2(SIZE);
     intSerialArray   exactJ2(SIZE);
     intSerialArray   exactK2(SIZE);
     intSerialArray   exactL2(SIZE);
     floatSerialArray exactA(SIZE,SIZE);
     floatSerialArray exactB(SIZE,SIZE);
     floatSerialArray exactC(SIZE,SIZE);
     floatSerialArray exactD(SIZE,SIZE);

  // Initialize the parallel and serial arrays
     A = 10;
     B = 20;
     C = 50;
     D = 100;
     exactA = 10;
     exactB = 20;
     exactC = 50;
     exactD = 100;

  // Use parallel scalar indexing to initialize an example problem
     int i;
     for (i=0; i < SIZE; i++)
        {
          int value = SIZE-(i+1);
          I1(i) = value;
          J1(i) = value;
          K1(i) = value;
          L1(i) = value;
          I2(i) = value;
          J2(i) = value;
          K2(i) = value;
          L2(i) = value;

          exactI1(i) = value;
          exactJ1(i) = value;
          exactK1(i) = value;
          exactL1(i) = value;
          exactI2(i) = value;
          exactJ2(i) = value;
          exactK2(i) = value;
          exactL2(i) = value;

       // Initialize the diagonal of the 2D arrays (parallel and serial) to be indirectly indexed
          A(i,i) = value+2;
          B(i,i) = value+5;
          C(i,i) = value+9;
          D(i,i) = value+9;

          exactA(i,i) = value+2;
          exactB(i,i) = value+5;
          exactC(i,i) = value+9;
          exactD(i,i) = value+9;
        }

  // Build the empty vectors to hold the indirect arrays (pointers to intArrays)
     vector<intArray*> IList;
     vector<intArray*> JList;
     vector<intArray*> KList;
     vector<intArray*> LList;

  // Form vectors of indirection arrays for each operand
     IList.push_back(&I1);
     IList.push_back(&I2);
     JList.push_back(&J1);
     JList.push_back(&J2);
     KList.push_back(&K1);
     KList.push_back(&K2);
     LList.push_back(&L1);
     LList.push_back(&L2);

  // Form a vector of vectors of indirection arrays
     vector<vector<intArray*> > intArrayListForAllOperands;
     intArrayListForAllOperands.push_back(IList);
     intArrayListForAllOperands.push_back(JList);
     intArrayListForAllOperands.push_back(KList);
     intArrayListForAllOperands.push_back(LList);

  // Form a vector of operands that will be addressed using the indirection arrays
     vector<floatArray*> floatArrayList; // See if this might work = { &A, &B };
     floatArrayList.push_back(&A);
     floatArrayList.push_back(&B);
     floatArrayList.push_back(&C);
     floatArrayList.push_back(&D);

#if (NUMBER_OF_OPERANDS == 0)
  // Call operator to compute: nothing (just to make sure that ZERO is a valid input);
     interpolate ( 0, floatArrayList, intArrayListForAllOperands );
#endif

#if (NUMBER_OF_OPERANDS == 1)
  // Call operator to compute: A(I1,I2) = 1;
     interpolate ( 1, floatArrayList, intArrayListForAllOperands );
     exactA(exactI1,exactI2) = 1;
#endif

#if (NUMBER_OF_OPERANDS == 2)
  // Call operator to compute: A(I1,I2) = B(J1,J2);
     interpolate ( 2, floatArrayList, intArrayListForAllOperands );
     exactA(exactI1,exactI2) = exactB(exactJ1,exactJ2);
#endif

#if (NUMBER_OF_OPERANDS == 3)
  // Call operator to compute: A(I1,I2) = B(J1,J2) + C(K1,K2);
     interpolate ( 3, floatArrayList, intArrayListForAllOperands );
     exactA(exactI1,exactI2) = exactB(exactJ1,exactJ2) + exactC(exactK1,exactK2);
#endif

#if (NUMBER_OF_OPERANDS == 4)
  // Call operator to compute: A(I1,I2) = B(J1,J2) * C(K1,K2) + (1.0 - B(J1,J2)) * D(K1,K2);
     interpolate ( 4, floatArrayList, intArrayListForAllOperands );
     exactA(exactI1,exactI2) =        exactB(exactJ1,exactJ2)  * exactC(exactK1,exactK2) +
                               (1.0 - exactB(exactJ1,exactJ2)) * exactD(exactL1,exactL2);
#endif

  // Build a partition for a single processor distribution
     Partitioning_Type singleProcessorDistribution(Range(0,0));
     singleProcessorDistribution.display("singleProcessorDistribution");

  // Move A onto processor a single processor (processor 0) so that we can compute the error
     A.partition(singleProcessorDistribution);

  // Display the values from each array (the parallel and serial arrays should be the same)
     A.getSerialArrayPointer()->display("A.getSerialArrayPointer()");
     exactA.display("exactA");

  // Compute the error on processor 0 only (since that is where we repartitioned the parallel array)
     float errorNorm = 0.0;
     if (Communication_Manager::localProcessNumber() == 0)
        {
          floatSerialArray error = exactA - *(A.getSerialArrayPointer());

       // Compute max norm of error
          errorNorm = sum(abs(error));
        }

     printf ("Error should be zero: error = %f \n",errorNorm);
   }

int
main( int argc, char *argv[])
   {
     int theNumberOfProcessors;
     Optimization_Manager::Initialize_Virtual_Machine ("", theNumberOfProcessors,argc,argv);

     interpolationTest();

     printf ("Program Terminated Normally! \n");

#if 0
  // Call the diagnostics mechanism to display memory usage
     Diagnostic_Manager::report();

  // Turn on the mechanism to remove all internal memory in use after the last array is deleted
     Diagnostic_Manager::setSmartReleaseOfInternalMemory(ON);

  // Exit from within the global release mechanism
     Diagnostic_Manager::setExitFromGlobalMemoryRelease();
#endif

     return 0;
   }












